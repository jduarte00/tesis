{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173b9d9f-fa22-4146-a7e5-c9ffe7ff7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance\n",
    "from numpy import linalg as LA\n",
    "\n",
    "\n",
    "from __future__ import division, print_function\n",
    "from builtins import reversed\n",
    "from builtins import map, zip\n",
    "from collections.abc import MutableSequence, Sequence\n",
    "import copy\n",
    "from math import ceil\n",
    "from numbers import Complex, Integral, Real\n",
    "import sys\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28b1ca-d1fb-4455-b3de-8a012c3cb1f4",
   "metadata": {},
   "source": [
    "Copio a continuación las funciones de la librería PyRMT tal cuál están en el github, con algunos comentarios mios pero sin ninguna modificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b34a8d-57b9-44df-81fd-c682580e9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES AUXILIARES PYRMT\n",
    "\n",
    "def checkDesignMatrix(X):\n",
    "    \"\"\"\n",
    "       Parameters\n",
    "       ----------\n",
    "       X: a matrix of shape (T, N), where T denotes the number\n",
    "           of samples and N labels the number of features.\n",
    "           If T < N, a warning is issued to the user, and the transpose\n",
    "           of X is considered instead.\n",
    "       Returns:\n",
    "       T: type int\n",
    "       N: type int\n",
    "       transpose_flag: type bool\n",
    "           Specify if the design matrix X should be transposed\n",
    "           in view of having less rows than columns.       \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        assert isinstance(X, (np.ndarray, pd.DataFrame, pd.Series))\n",
    "    except AssertionError:\n",
    "        raise\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Código para convertir a X en un array, si es que no lo es  \n",
    "    X = np.asarray(X, dtype=float)\n",
    "    # Código para convertir a X en un array de numpy de dos dimensiones \n",
    "    X = np.atleast_2d(X)\n",
    "\n",
    "    if X.shape[0] < X.shape[1]:\n",
    "        warnings.warn(\"The Marcenko-Pastur distribution pertains to \"\n",
    "                      \"the empirical covariance matrix of a random matrix X \"\n",
    "                      \"of shape (T, N). It is assumed that the number of \"\n",
    "                      \"samples T is assumed higher than the number of \"\n",
    "                      \"features N. The transpose of the matrix X submitted \"\n",
    "                      \"at input will be considered in the cleaning schemes \"\n",
    "                      \"for the corresponding correlation matrix.\", UserWarning)\n",
    "        \n",
    "        T, N = reversed(X.shape)\n",
    "        transpose_flag = True\n",
    "    else:\n",
    "        T, N = X.shape\n",
    "        transpose_flag = False\n",
    "        \n",
    "    return T, N, transpose_flag\n",
    "\n",
    "def xiHelper(x, q, E):\n",
    "    \"\"\"Helper function to the rotationally-invariant, optimal shrinkage\n",
    "       estimator of the true correlation matrix (implemented via function\n",
    "       optimalShrinkage of the present module). \n",
    "       Parameters\n",
    "       ----------\n",
    "       x: type derived from numbers.Real\n",
    "           Would typically be expected to be an eigenvalue from the\n",
    "           spectrum of correlation matrix E. The present function\n",
    "           can however handle an arbitrary floating-point number.\n",
    "       q: type derived from numbers.Real\n",
    "           The number parametrizing a Marcenko-Pastur spectrum.\n",
    "       E: type numpy.ndarray\n",
    "           Symmetric correlation matrix associated with the \n",
    "           Marcenko-Pastur parameter q specified above.\n",
    "       Returns\n",
    "       -------\n",
    "       xi: type float\n",
    "           Cleaned eigenvalue of the true correlation matrix C underlying\n",
    "           the empirical correlation E (the latter being corrupted \n",
    "           with in-sample noise). This cleaned version is computed\n",
    "           assuming no prior knowledge on the structure of the true\n",
    "           eigenvectors (thereby leaving the eigenvectors of E unscathed). \n",
    "       References\n",
    "       ----------\n",
    "       * \"Rotational invariant estimator for general noisy matrices\",\n",
    "         J. Bun, R. Allez, J.-P. Bouchaud and M. Potters\n",
    "         arXiv: 1502.06736 [cond-mat.stat-mech]\n",
    "       * \"Cleaning large Correlation Matrices: tools from Random Matrix Theory\",\n",
    "         J. Bun, J.-P. Bouchaud and M. Potters\n",
    "         arXiv: 1610.08104 [cond-mat.stat-mech]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        assert isinstance(x, Real)\n",
    "        assert isinstance(q, Real)\n",
    "        assert isinstance(E, np.ndarray) and E.shape[0] == E.shape[1]\n",
    "        assert np.allclose(E.transpose(1, 0), E)\n",
    "    except AssertionError:\n",
    "        raise\n",
    "        sys.exit(1)\n",
    "\n",
    "    N = E.shape[0]\n",
    "    \n",
    "    # esta z es z_k en el paper Box1 (ESTÁ BIEN)\n",
    "    z = x - 1j / np.sqrt(N)\n",
    "    \n",
    "    # esta s_k es en realidad s_k(z_k) en el paper (ESTA DIFERENTE)\n",
    "    s = stieltjes(z, E)\n",
    "    \n",
    "    #xi es \\xi_l^{RIE} en el paper (ESTA IGUAL)\n",
    "    xi = x / abs(1 - q + q * z * s)**2\n",
    "   \n",
    "    return xi\n",
    "\n",
    "def stieltjes(z, E):\n",
    "    \"\"\"\n",
    "       Parameters\n",
    "       ----------\n",
    "       z: complex number\n",
    "       E: square matrix\n",
    "       Returns\n",
    "       -------\n",
    "       A complex number, the resolvent of square matrix E, \n",
    "       also known as its Stieltjes transform.\n",
    "       Reference\n",
    "       ---------\n",
    "       \"Financial Applications of Random Matrix Theory: a short review\",\n",
    "       J.-P. Bouchaud and M. Potters\n",
    "       arXiv: 0910.1205 [q-fin.ST]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        assert isinstance(z, Complex)\n",
    "        \n",
    "        assert isinstance(E, (np.ndarray, pd.DataFrame))\n",
    "        E = np.asarray(E, dtype=float)\n",
    "        E = np.atleast_2d(E)\n",
    "        assert E.shape[0] == E.shape[1]\n",
    "    except AssertionError:\n",
    "        raise\n",
    "        sys.exit(1)\n",
    "\n",
    "    #AQUÍ ES DONDE SE ESTÁ CALCULANDO DE FORMA DISTINTA LO QUE SE CONOCE COMO $S_k$ EN EL PAPER\n",
    "    # Y AQUÍ SE LE DENOMINA ret\n",
    "    N = E.shape[0]\n",
    "    \n",
    "    ret = z * np.eye(N, dtype=float) - E\n",
    "    \n",
    "   \n",
    "    ret = np.trace(ret) / N\n",
    "   \n",
    "\n",
    "    return ret\n",
    "\n",
    "def gammaHelper(x, q, N, lambda_N, inverse_wishart=False):\n",
    "    \"\"\"Helper function to optimalShrinkage function defined below.\n",
    "       The eigenvalue to the cleaned estimator of a true correlation\n",
    "       matrix are computed via the function xiHelper defined above in\n",
    "       the module at hand. \n",
    "       \n",
    "       It is known however that when N is not very large\n",
    "       a systematic downward bias affects the xiHelper estimator for small\n",
    "       eigenvalues of the noisy empirical correlation matrix. This bias\n",
    "       can be heuristically corrected by computing\n",
    "       xi_hat = xi_RIE * max(1, Gamma),\n",
    "       with Gamma evaluated by the function gammaHelper herewith.\n",
    "       Parameters\n",
    "       ----------\n",
    "       x: type float or any other type derived from numbers.Real\n",
    "           Typically an eigenvalue from the spectrum of a sample\n",
    "           estimate of the correlation matrix associated to some\n",
    "           design matrix X. However, the present function supports\n",
    "           any arbitrary floating-point number x at input.\n",
    "       q: type derived from numbers.Real\n",
    "           Parametrizes a Marcenko-Pastur spectrum.\n",
    "       N: type derived from numbers.Integral\n",
    "           Dimension of a correlation matrix whose debiased, \n",
    "           rotationally-invariant estimator is to be assessed via\n",
    "           the function RIE (see below), of which the present function\n",
    "           is a helper.\n",
    "       lambda_N: type derived from numbers.Real\n",
    "           Smallest eigenvalue from the spectrum of an empirical\n",
    "           estimate to a correlation matrix.\n",
    "        \n",
    "       inverse_wishart: type bool default: False\n",
    "            Wether to use inverse wishart regularization\n",
    "       Returns\n",
    "       ------\n",
    "       Gamma: type float\n",
    "           Upward correction factor for computing a debiased \n",
    "           rotationally-invariant estimator of a true underlying \n",
    "           correlation matrix. \n",
    "       Reference\n",
    "       ---------\n",
    "       \"Cleaning large Correlation Matrices: tools from Random Matrix Theory\",\n",
    "        J. Bun, J.-P. Bouchaud and M. Potters\n",
    "        arXiv: 1610.08104 [cond-mat.stat-mech]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        assert isinstance(x, Real)\n",
    "        assert isinstance(q, Real)\n",
    "        assert isinstance(N, Integral)\n",
    "        assert isinstance(lambda_N, Real)\n",
    "    except AssertionError:\n",
    "        raise\n",
    "        sys.exit(1)\n",
    "\n",
    "    z = x - 1j / np.sqrt(N)\n",
    "  \n",
    "    # Este lambda plus está igual  que en el paper (ESTÁ BIEN)\n",
    "    lambda_plus = (1 + np.sqrt(q))**2\n",
    "\n",
    "    lambda_plus /= (1 - np.sqrt(q))**2\n",
    "\n",
    "    lambda_plus *= lambda_N\n",
    "\n",
    "    # Este sigma cuadrada está igual que en el N (ESTÁ BIEN)\n",
    "    sigma_2 = lambda_N / (1 - np.sqrt(q))**2\n",
    "\n",
    "    \n",
    "    # gmp defined below stands for the Stieltjes transform of the\n",
    "    # rescaled Marcenko-Pastur density, evaluated at z\n",
    "    # esta función es la (18) y es distinta a la del paper ( NOTAR QUE EN EL PAPER \n",
    "    # LA PARTE QUE SE RESTA ESTÁ COMO \\SQRT{ z - \\lambda_n} \\times \\sqrt{z - \\lambda_+})\n",
    "    # mientras que aquí primero se multiplican los dos valores y luego se saca la raíz cuadrada\n",
    "    gmp = z + sigma_2 * (q - 1) - np.sqrt((z - lambda_N) * (z - lambda_plus))    \n",
    "    gmp /= 2 * q * sigma_2 * z\n",
    "    # Este es el Gamma_k y ESTÁ IGUAL (más adelante se realiza la división entre lambda_k que está como x)\n",
    "    Gamma = abs(1 - q + q * z * gmp)**2\n",
    "    Gamma *= sigma_2\n",
    "    \n",
    "    if inverse_wishart:\n",
    "        kappa = 2 * lambda_N / ((1 - q - lambda_N) ** 2 - 4 * q * lambda_N)\n",
    "        alpha_s = 1 / (1 + 2 * q * kappa)\n",
    "        denom = x / (1 + alpha_s * (x - 1.))\n",
    "        Gamma /= denom\n",
    "    else: \n",
    "        Gamma /= x\n",
    "\n",
    "    return Gamma\n",
    "\n",
    "\n",
    "# FUNCIÓN PRINCIPAL PYRMT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303bb198-dddf-48e3-b7f4-c7fd32b65de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:114: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:114: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/tmp/ipykernel_5619/842616512.py:114: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if method is not 'kernel':\n"
     ]
    }
   ],
   "source": [
    "def optimalShrinkage(X, return_covariance=False, method='rie'):\n",
    "    \"\"\"This function computes a cleaned, optimal shrinkage, \n",
    "       rotationally-invariant estimator (RIE) of the true correlation \n",
    "       matrix C underlying the noisy, in-sample estimate \n",
    "       E = 1/T X * transpose(X)\n",
    "       associated to a design matrix X of shape (T, N) (T measurements \n",
    "       and N features).\n",
    "       One approach to getting a cleaned estimator that predates the\n",
    "       optimal shrinkage, RIE estimator consists in inverting the \n",
    "       Marcenko-Pastur equation so as to replace the eigenvalues\n",
    "       from the spectrum of E by an estimation of the true ones.\n",
    "       This approach is known to be numerically-unstable, in addition\n",
    "       to failing to account for the overlap between the sample eigenvectors\n",
    "       and the true eigenvectors. How to compute such overlaps was first\n",
    "       explained by Ledoit and Peche (cf. reference below). Their procedure\n",
    "       was extended by Bun, Bouchaud and Potters, who also correct\n",
    "       for a systematic downward bias in small eigenvalues.\n",
    "       \n",
    "       It is this debiased, optimal shrinkage, rotationally-invariant\n",
    "       estimator that the function at hand implements.\n",
    "       \n",
    "       In addition to above method, this funtion also provides access to:  \n",
    "       - The finite N regularization of the optimal RIE for small eigenvalues\n",
    "         as provided in section 8.1 of [3] a.k.a the inverse wishart (IW) regularization.\n",
    "       - The direct kernel method of O. Ledoit and M. Wolf in their 2017 paper [4]. \n",
    "         This is a direct port of their Matlab code.\n",
    "        \n",
    "         \n",
    "       Parameters\n",
    "       ----------\n",
    "       X: design matrix, of shape (T, N), where T denotes the number\n",
    "           of samples (think measurements in a time series), while N\n",
    "           stands for the number of features (think of stock tickers).\n",
    "           \n",
    "       return_covariance: type bool (default: False)\n",
    "           If set to True, compute the standard deviations of each individual\n",
    "           feature across observations, clean the underlying matrix\n",
    "           of pairwise correlations, then re-apply the standard\n",
    "           deviations and return a cleaned variance-covariance matrix.\n",
    "       \n",
    "       method: type string, optional (default=\"rie\")\n",
    "           - If \"rie\" : optimal shrinkage in the manner of Bun & al.\n",
    "            with no regularisation  \n",
    "           - If \"iw\" : optimal shrinkage in the manner of Bun & al.\n",
    "            with the so called Inverse Wishart regularization\n",
    "           - If 'kernel': Direct kernel method of Ledoit  Wolf.\n",
    "       Returns\n",
    "       -------\n",
    "       E_RIE: type numpy.ndarray, shape (N, N)\n",
    "           Cleaned estimator of the true correlation matrix C. A sample\n",
    "           estimator of C is the empirical covariance matrix E \n",
    "           estimated from X. E is corrupted by in-sample noise.\n",
    "           E_RIE is the optimal shrinkage, rotationally-invariant estimator \n",
    "           (RIE) of C computed following the procedure of Joel Bun \n",
    "           and colleagues (cf. references below).\n",
    "           \n",
    "           If return_covariance=True, E_clipped corresponds to a cleaned\n",
    "           variance-covariance matrix.\n",
    "       References\n",
    "       ----------\n",
    "       1 \"Eigenvectors of some large sample covariance matrix ensembles\",\n",
    "         O. Ledoit and S. Peche\n",
    "         Probability Theory and Related Fields, Vol. 151 (1), pp 233-264\n",
    "       2 \"Rotational invariant estimator for general noisy matrices\",\n",
    "         J. Bun, R. Allez, J.-P. Bouchaud and M. Potters\n",
    "         arXiv: 1502.06736 [cond-mat.stat-mech]\n",
    "       3 \"Cleaning large Correlation Matrices: tools from Random Matrix Theory\",\n",
    "         J. Bun, J.-P. Bouchaud and M. Potters\n",
    "         arXiv: 1610.08104 [cond-mat.stat-mech]\n",
    "       4 \"Direct Nonlinear Shrinkage Estimation of Large-Dimensional Covariance Matrices (September 2017)\", \n",
    "         O. Ledoit and M. Wolf https://ssrn.com/abstract=3047302 or http://dx.doi.org/10.2139/ssrn.3047302\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        assert isinstance(return_covariance, bool)\n",
    "    except AssertionError:\n",
    "        raise\n",
    "        sys.exit(1)\n",
    "\n",
    "    T, N, transpose_flag = checkDesignMatrix(X)\n",
    "    if transpose_flag:\n",
    "        X = X.T\n",
    "      \n",
    "    # Si se quiere la matriz de correlación limpia, los datos SÍ se estandarizan, de lo contrario no se estandarizan\n",
    "    if not return_covariance:\n",
    "      print(\"sí estandarize\")\n",
    "      X = StandardScaler(with_mean=False,with_std=True).fit_transform(X)\n",
    "\n",
    "    #ec = EmpiricalCovariance(store_precision=False,assume_centered=True)\n",
    "    #ec.fit(X)\n",
    "    # COMO YO USO NUMPY PARA OBTENER LA MATRIZ DE CORRELAICÓN MÁS RÁPIDO, HAGO ESTE PEQUEÑO CAMBIO AQUÍ\n",
    "    # PARA CACULAR LA MATRIZ CON NUMPY Y NO CON SCIKIT LEARN\n",
    "    #E = ec.covariance_\n",
    "    E = np.corrcoef(X.T)\n",
    "    \n",
    "\n",
    "    if return_covariance:\n",
    "        inverse_std = 1./np.sqrt(np.diag(E))\n",
    "        E *= inverse_std\n",
    "        E *= inverse_std.reshape(-1, 1)\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eigh(E)\n",
    "    eigvecs = eigvecs.T\n",
    "    eigen_val_sample, eigen_vec_sample = LA.eig(E)\n",
    "    q = N / float(T)\n",
    "    lambda_N = eigvals[0]  # The smallest empirical eigenvalue,\n",
    "                           # given that the function used to compute\n",
    "                           # the spectrum of a Hermitian or symmetric\n",
    "                           # matrix - namely np.linalg.eigh - returns\n",
    "                           # the eigenvalues in ascending order.\n",
    "    lambda_hats = None\n",
    "\n",
    "    \n",
    "    if method is not 'kernel':\n",
    "        use_inverse_wishart = (method == 'iw')\n",
    "        xis = map(lambda x: xiHelper(x, q, E), eigvals)\n",
    "        Gammas = map(lambda x: gammaHelper(x, q, N, lambda_N, inverse_wishart=use_inverse_wishart), eigvals)\n",
    "        # Aquí se define el stepwise function ( y está igual que en el paper)\n",
    "        xi_hats = map(lambda a, b: a * b if b > 1 else a, xis, Gammas)\n",
    "        lambda_hats = xi_hats\n",
    "    else:\n",
    "         lambda_hats = directKernel(q, T, N, eigvals)\n",
    "        \n",
    "    E_RIE = np.zeros((N, N), dtype=float)\n",
    "    \n",
    "    for lambda_hat, eigvec in zip(lambda_hats, eigvecs):\n",
    "        \n",
    "        eigvec = eigvec.reshape(-1, 1)\n",
    "        E_RIE += lambda_hat * eigvec.dot(eigvec.T)\n",
    "        \n",
    "    # EN MI IMPLEMENTACIÓN YA NO MODIFICO LA MATRIZ PARA QUE LA DIAGONAL SEA EXACTAMENTE UNO\n",
    "    # QUE ES LO QUE SE HACE ADELANTE, RAZÓN POR LA CUAL IMPRIMO LA MATRIZ EN ESTE PUNTO ANTES \n",
    "    # DE QUE LA MODIFIQUEN PARA VERIFICAR QUE LOS RESULTADOS SEAN LOS MISMOS\n",
    "    print(E_RIE)\n",
    "    print(LA.eig)\n",
    "    tmp = 1./np.sqrt(np.diag(E_RIE))\n",
    "    E_RIE *= tmp\n",
    "    E_RIE *= tmp.reshape(-1, 1)\n",
    "    \n",
    "    if return_covariance:\n",
    "        std = 1./inverse_std\n",
    "        E_RIE *= std\n",
    "        E_RIE *= std.reshape(-1, 1)\n",
    "    \n",
    "\n",
    "    return E_RIE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd22f0-1320-42a5-bb11-f5368012cedd",
   "metadata": {},
   "source": [
    "En la implementación de PyRMT hay dos cosas que cambian con respecto al paper:\n",
    " - El cálculo de $S_k(z_k)$\n",
    " - El cálculo de $g_{mp}(z)$\n",
    "\n",
    "A continuación escribo mi implementación calculando estas dos variables tal cuál se hace en el PyRMT para mostrar que son los únicos dos lugares donde la implementación difiere, y que se utiliza la misma forma de cálculo se obtienen entonces los mismos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d941a804-afa7-4bea-a9fe-7a86d5287592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCION AUXILIAR MI IMPLEMENTACION\n",
    "\n",
    "def returnsStandardization(returns):\n",
    "    returns_wth_mean = returns - np.mean(returns, axis=0)\n",
    "    hat_sigma = np.sqrt((returns_wth_mean**2).sum(axis=1))\n",
    "    r_tilde = returns_wth_mean.divide(hat_sigma, axis=0)\n",
    "    X = r_tilde / np.std(r_tilde)\n",
    "    return X\n",
    "\n",
    "\n",
    "# FUNCION PRINCIPAL MI IMPLEMENTACION\n",
    "\n",
    "\n",
    "def get_rie(returns, normalize=False):\n",
    "    def get_s_k(index_lambda, N):\n",
    "        return 1/N * (sum(1/(z_k[index_lambda] - lambdas)) - 1/(z_k[index_lambda] - lambdas[index_lambda]))\n",
    "\n",
    "    # T is the number of observations, N is the number of assets\n",
    "    T, N = returns.shape\n",
    "    RIE_estimator = np.zeros((N, N), dtype=float)\n",
    "    if normalize:\n",
    "        returns = returnsStandardization(returns)\n",
    "    # Calculation of the sample correlation matrix\n",
    "    E = np.corrcoef(returns.T)\n",
    "    # The eigenvalues and eigenvectors of the returns are obtained\n",
    "    lambdas, u_ks = LA.eigh(E)\n",
    "    u_ks = u_ks.T\n",
    "    n_lambda = lambdas[0]\n",
    "    q = float(N/T)\n",
    "    sigma_sq = (n_lambda)/(1 - np.sqrt(q))**2\n",
    "    lambda_plus = n_lambda*((1+np.sqrt(q))/(1 - np.sqrt(q)))**2\n",
    "    # Get z_k\n",
    "    z_k = lambdas - (1j / np.sqrt(N))\n",
    "    # Get s_k(z_k)\n",
    "    s_k = z_k - 1\n",
    "    #s_k = list(map(lambda index_lambda: get_s_k(\n",
    "    #    index_lambda, N), np.argsort(lambdas)))\n",
    "    # Get \\xi_k^{RIE}\n",
    "    xi_k = lambdas / np.abs(1 - q + q * z_k * s_k)**2\n",
    "    # Get stieltjes g_{mp}(z)\n",
    "    #g_mp = (z_k + sigma_sq*(q-1) - (np.sqrt(z_k - n_lambda)\n",
    "    #        * np.sqrt(z_k - lambda_plus)))/(2*q*z_k*sigma_sq)\n",
    "    g_mp = (z_k + sigma_sq*(q-1) - (np.sqrt((z_k - n_lambda)* (z_k - lambda_plus))))/(2*q*z_k*sigma_sq)\n",
    "    # Get gamma_k(z_k)\n",
    "    gamma_k = sigma_sq * ((np.abs(1 - q + q*z_k*g_mp)**2)/(lambdas))\n",
    "    # Get \\hat{xh}_k\n",
    "    xi_hat = list(map(lambda xi, gamma: xi *\n",
    "                  gamma if gamma > 1 else xi, xi_k, gamma_k))\n",
    "    # Get RIE\n",
    "    for xi, u_i in zip(xi_hat, u_ks):\n",
    "        RIE_estimator += xi*(u_i.reshape(-1, 1) @ u_i.reshape(-1, 1).T)\n",
    "\n",
    "    return RIE_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271276e5-a9f5-4c45-8f71-8f6a2b5bf51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n"
     ]
    }
   ],
   "source": [
    "test_set = yfinance.download(['FB', 'AOS', 'ABT', 'GOOGL'], start=\"2020-01-01\", end = \"2021-12-31\")\n",
    "returns = test_set['Close'].pct_change(periods=1).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f20742d-9783-41cd-9da4-748886ab3972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT</th>\n",
       "      <th>AOS</th>\n",
       "      <th>FB</th>\n",
       "      <th>GOOGL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>-0.012191</td>\n",
       "      <td>-0.008792</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>-0.005231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>0.026654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>-0.005559</td>\n",
       "      <td>-0.006716</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>-0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.004076</td>\n",
       "      <td>-0.001479</td>\n",
       "      <td>0.010138</td>\n",
       "      <td>0.007118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>0.002668</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.010498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.014338</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>0.016528</td>\n",
       "      <td>0.023318</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>0.006738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>-0.006998</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.008245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>-0.009474</td>\n",
       "      <td>-0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>-0.001346</td>\n",
       "      <td>-0.006060</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>-0.003099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ABT       AOS        FB     GOOGL\n",
       "Date                                              \n",
       "2020-01-03 -0.012191 -0.008792 -0.005291 -0.005231\n",
       "2020-01-06  0.005239  0.006336  0.018834  0.026654\n",
       "2020-01-07 -0.005559 -0.006716  0.002164 -0.001932\n",
       "2020-01-08  0.004076 -0.001479  0.010138  0.007118\n",
       "2020-01-09  0.002668 -0.004443  0.014311  0.010498\n",
       "...              ...       ...       ...       ...\n",
       "2021-12-23  0.001223  0.014338  0.014495  0.003425\n",
       "2021-12-27  0.016528  0.023318  0.032633  0.006738\n",
       "2021-12-28 -0.006998  0.009917  0.000116 -0.008245\n",
       "2021-12-29  0.005126  0.003156 -0.009474 -0.000218\n",
       "2021-12-30 -0.001346 -0.006060  0.004141 -0.003099\n",
       "\n",
       "[503 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cac3ac-d48a-46d8-90ff-b91dc28fd4dc",
   "metadata": {},
   "source": [
    "Estandarizo los retornos como se describe en el artículo (a las dos funciones se les pasara este input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960036bc-c238-4631-9e8c-91bef833d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_estand = returnsStandardization(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf68b52-5dad-4ee1-b9a1-ad78280390dd",
   "metadata": {},
   "source": [
    "A continuación calculo el RIE mediante mi implementación pero con la misma forma que usa PyRMT para calcular $S_k(z_k)$ y $g_{mp}(z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "213ba2e0-f1f3-472a-9917-15168c74c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.02519059 0.09057524 0.18712667 0.20985177]\n",
      " [0.09057524 1.01883383 0.11750129 0.13346603]\n",
      " [0.18712667 0.11750129 1.17695412 0.33697996]\n",
      " [0.20985177 0.13346603 0.33697996 1.21128441]]\n"
     ]
    }
   ],
   "source": [
    "print(get_rie(returns_estand, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f6e39-ec4a-44a7-8c92-bedb027eebbf",
   "metadata": {},
   "source": [
    "A continuación utilizo la implementación de PyRMT. La primer matriz que se muestra es el RIE antes de modificar las entradas para que se obtengan unos en la diagonal. **Es posible verificar entonces que el resultado es el mismo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65720e38-5aa0-4c7c-8177-009b9b12a19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.02519059 0.09057524 0.18712667 0.20985177]\n",
      " [0.09057524 1.01883383 0.11750129 0.13346603]\n",
      " [0.18712667 0.11750129 1.17695412 0.33697996]\n",
      " [0.20985177 0.13346603 0.33697996 1.21128441]]\n",
      "<function eig at 0x7f6d4c1d9120>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.08862484, 0.17035451, 0.18831602],\n",
       "       [0.08862484, 1.        , 0.10730284, 0.12014232],\n",
       "       [0.17035451, 0.10730284, 1.        , 0.28222875],\n",
       "       [0.18831602, 0.12014232, 0.28222875, 1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalShrinkage(returns_estand, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73b618-cf53-4ea7-aba6-8b6425883283",
   "metadata": {},
   "source": [
    "Se vuelve a definir la función pero utilizando la forma que indica el paper para calcular  $S_k(z_k)$ y $g_{mp}(z)$ (Se ponen comentadas la forma que usa PyRMt para comparación):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29db37b4-c974-4cdb-80bc-3e6731e7e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCION AUXILIAR MI IMPLEMENTACION\n",
    "\n",
    "def returnsStandardization(returns):\n",
    "    returns_wth_mean = returns - np.mean(returns, axis=0)\n",
    "    hat_sigma = np.sqrt((returns_wth_mean**2).sum(axis=1))\n",
    "    r_tilde = returns_wth_mean.divide(hat_sigma, axis=0)\n",
    "    X = r_tilde / np.std(r_tilde)\n",
    "    return X\n",
    "\n",
    "\n",
    "# FUNCION PRINCIPAL MI IMPLEMENTACION\n",
    "\n",
    "\n",
    "def get_rie(returns, normalize=False):\n",
    "    def get_s_k(index_lambda, N):\n",
    "        return 1/N * (sum(1/(z_k[index_lambda] - lambdas)) - 1/(z_k[index_lambda] - lambdas[index_lambda]))\n",
    "\n",
    "    # T is the number of observations, N is the number of assets\n",
    "    T, N = returns.shape\n",
    "    RIE_estimator = np.zeros((N, N), dtype=float)\n",
    "    if normalize:\n",
    "        returns = returnsStandardization(returns)\n",
    "    # Calculation of the sample correlation matrix\n",
    "    E = np.corrcoef(returns.T)\n",
    "    # The eigenvalues and eigenvectors of the returns are obtained\n",
    "    lambdas, u_ks = LA.eigh(E)\n",
    "    u_ks = u_ks.T\n",
    "    n_lambda = lambdas[0]\n",
    "    q = float(N/T)\n",
    "    sigma_sq = (n_lambda)/(1 - np.sqrt(q))**2\n",
    "    lambda_plus = n_lambda*((1+np.sqrt(q))/(1 - np.sqrt(q)))**2\n",
    "    # Get z_k\n",
    "    z_k = lambdas - (1j / np.sqrt(N))\n",
    "    # Get s_k(z_k)\n",
    "    #s_k = z_k - 1\n",
    "    s_k = list(map(lambda index_lambda: get_s_k(\n",
    "        index_lambda, N), np.argsort(lambdas)))\n",
    "    # Get \\xi_k^{RIE}\n",
    "    xi_k = lambdas / np.abs(1 - q + q * z_k * s_k)**2\n",
    "    # Get stieltjes g_{mp}(z)\n",
    "    g_mp = (z_k + sigma_sq*(q-1) - (np.sqrt(z_k - n_lambda)\n",
    "            * np.sqrt(z_k - lambda_plus)))/(2*q*z_k*sigma_sq)\n",
    "    #g_mp = (z_k + sigma_sq*(q-1) - (np.sqrt((z_k - n_lambda)* (z_k - lambda_plus))))/(2*q*z_k*sigma_sq)\n",
    "    # Get gamma_k(z_k)\n",
    "    gamma_k = sigma_sq * ((np.abs(1 - q + q*z_k*g_mp)**2)/(lambdas))\n",
    "    # Get \\hat{xh}_k\n",
    "    xi_hat = list(map(lambda xi, gamma: xi *\n",
    "                  gamma if gamma > 1 else xi, xi_k, gamma_k))\n",
    "    # Get RIE\n",
    "    for xi, u_i in zip(xi_hat, u_ks):\n",
    "        RIE_estimator += xi*(u_i.reshape(-1, 1) @ u_i.reshape(-1, 1).T)\n",
    "\n",
    "    return RIE_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f18b5a-9f7f-4be2-a116-6defd178a5ff",
   "metadata": {},
   "source": [
    "Vuelvo a correr la función con los mismos datos, **es posible observar que el resultado es diferente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20b2ebdb-889d-4ead-b4cb-e7be1ab3e4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00799956, 0.08946465, 0.15965291, 0.24226455],\n",
       "       [0.08946465, 1.00617941, 0.11209109, 0.14159726],\n",
       "       [0.15965291, 0.11209109, 1.04416625, 0.47395155],\n",
       "       [0.24226455, 0.14159726, 0.47395155, 1.05236458]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rie(returns_estand, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
